{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AgroForest.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdilger/TensorFlowNotebooks/blob/master/AgroForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJIpyTd50j0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# note delete for share\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f6F2MYxpR3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use logging to maintain more detailed information for reproducibility \n",
        "import logging\n",
        "\n",
        "def tfLog():\n",
        "  logging.basicConfig(level=logging.DEBUG, filename='myapp.log',\n",
        "                      format='%(asctime)s %(levelname)s:%(message)s')\n",
        "  try:\n",
        "    logging.debug('######################################')\n",
        "    logging.debug('Config Settings')\n",
        "    logging.debug('######################################')\n",
        "    logging.debug(\"Bucket:%s\",BUCKET) \n",
        "    logging.debug(\"Folder:%s\",FOLDER)\n",
        "    logging.debug('Training base:%s',TRAINING_BASE)\n",
        "    logging.debug('Eaval base:%s',EVAL_BASE) \n",
        "    logging.debug('Band order:%s',BANDS)\n",
        "    logging.debug('Response:%s',RESPONSE)\n",
        "    logging.debug('Features:%s',FEATURES)\n",
        "    logging.debug('Kernal size:%d',KERNEL_SIZE)\n",
        "    logging.debug('FEATURES_DICT:%s',FEATURES_DICT)\n",
        "    logging.debug('Training size:%d',TRAIN_SIZE)\n",
        "    logging.debug('Eval size:%d',EVAL_SIZE)\n",
        "    logging.debug('batch size:%d',BATCH_SIZE)\n",
        "    logging.debug('Epochs:%d',EPOCHS)\n",
        "    logging.debug('Buffer size:%d',BUFFER_SIZE) \n",
        "    logging.debug('Optimizer:%s',OPTIMIZER) \n",
        "    # logging.debug('Loss:',LOSS)\n",
        "    # logging.debug('Other metrics:',METRICS)\n",
        "  except Exception as e:\n",
        "    print('logging failed')\n",
        "    print(e.args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neIa46CpciXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cloud authentication.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jat01FEoUMqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "try:\n",
        "    ee.Initialize()\n",
        "except Exception as e:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf706y6TDtnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RnZzcYhcpsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensorflow setup.\n",
        "# %tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "# tf.enable_eager_execution()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obDDH1eDzsch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INSERT YOUR BUCKET HERE:\n",
        "BUCKET = 'tf-agro-forest'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qs3qZG04u0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import backend\n",
        "# dice coeff and dice loss from Biplov\n",
        "def dice_coeff(y_true, y_pred, smooth=1):\n",
        "    y_true_f = backend.flatten(y_true)\n",
        "    y_pred_f = backend.flatten(y_pred)\n",
        "    intersection = backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (backend.sum(y_true_f) + backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "# soft dice loss function from Kel\n",
        "# based on https://arxiv.org/pdf/1707.03237.pdf \n",
        "def dice_loss_soft(y_true, y_pred, smooth=1):\n",
        "    intersection = backend.sum(backend.abs(y_true * y_pred), axis=-1)\n",
        "    true_sum = backend.sum(backend.square(y_true),-1) \n",
        "    pred_sum = backend.sum(backend.square(y_pred),-1)\n",
        "    return 1 - ((2. * intersection + smooth) / (true_sum + pred_sum + smooth))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmfKLl9XcnGJ",
        "colab_type": "text"
      },
      "source": [
        "## Set other global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psz7wJKalaoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import metrics\n",
        "# Specify names locations for outputs in Cloud Storage. \n",
        "FOLDER = 'jdilger/training_data' \n",
        "TRAINING_BASE = 'training_patches_updated_noconst_20_kernalsize_4'\n",
        "EVAL_BASE = 'testing_patches_updated_noconst_20_kernalsize_4'\n",
        "\n",
        "# Specify inputs (Landsat bands) to the model and the response variable.\n",
        "  \n",
        "BANDS =['blue_stdDev', 'green_stdDev', 'red_stdDev', 're1_stdDev', 're2_stdDev', 're3_stdDev',\n",
        "        'nir_stdDev', 'swir1_stdDev', 'swir2_stdDev', 'blue_stdDev_1', 'green_stdDev_1', 'red_stdDev_1',\n",
        "        're1_stdDev_1', 're2_stdDev_1', 're3_stdDev_1', 'nir_stdDev_1', 'swir1_stdDev_1', 'swir2_stdDev_1',\n",
        "        'blue_stdDev_2', 'green_stdDev_2', 'red_stdDev_2', 're1_stdDev_2', 're2_stdDev_2', 're3_stdDev_2', \n",
        "        'nir_stdDev_2', 'swir1_stdDev_2', 'swir2_stdDev_2', 'blue_stdDev_3', 'green_stdDev_3', 'red_stdDev_3',\n",
        "        're1_stdDev_3', 're2_stdDev_3', 're3_stdDev_3', 'nir_stdDev_3', 'swir1_stdDev_3', 'swir2_stdDev_3', \n",
        "         'blue', 'green', 'red', 're1', 're2', 're3', 'nir', 'swir1', 'swir2', 'blue_1', 'green_1',\n",
        "        'red_1', 're1_1', 're2_1', 're3_1', 'nir_1', 'swir1_1', 'swir2_1', 'blue_2', 'green_2', 'red_2', 're1_2',\n",
        "        're2_2', 're3_2', 'nir_2', 'swir1_2', 'swir2_2', 'blue_3', 'green_3', 'red_3', 're1_3', 're2_3', 're3_3',\n",
        "        'nir_3', 'swir1_3', 'swir2_3', 'blue_4', 'green_4', 'red_4', 're1_4', 're2_4', 're3_4',\n",
        "        'nir_4', 'swir1_4', 'swir2_4', 'blue_1_1', 'green_1_1', 'red_1_1', 're1_1_1', 're2_1_1',\n",
        "        're3_1_1', 'nir_1_1', 'swir1_1_1', 'swir2_1_1', 'blue_2_1', 'green_2_1', 'red_2_1', 're1_2_1',\n",
        "        're2_2_1', 're3_2_1', 'nir_2_1', 'swir1_2_1', 'swir2_2_1', 'blue_3_1', 'green_3_1', 'red_3_1', 're1_3_1',\n",
        "        're2_3_1', 're3_3_1', 'nir_3_1', 'swir1_3_1', 'swir2_3_1', 'VH', 'VV', 'VH_1', 'nd', 'VH_2', 'VV_1',\n",
        "        'VV_2', 'VH_3', 'VV_3', 'VH_1_1', 'nd_1', 'VH_2_1', 'VV_1_1', 'VV_2_1', 'VH_stdDev', 'VV_stdDev',\n",
        "        'VH_1_stdDev', 'nd_stdDev', 'VH_2_stdDev', 'VV_1_stdDev', 'VV_2_stdDev']\n",
        "\n",
        "RESPONSE = ['cocao','forest','seasonalAg'\n",
        "          ,'urban','water','banana','savana','orchard','mine','shrubland','sparseTree','bare'\n",
        "          ,'grassland','secondaryForest','nodata']\n",
        "FEATURES = BANDS + RESPONSE\n",
        "\n",
        "# Specify the size and shape of patches expected by the model.\n",
        "KERNEL_SIZE = 4\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
        "\n",
        "# Sizes of the training and evaluation datasets.\n",
        "TRAIN_SIZE = 7000\n",
        "EVAL_SIZE = 500\n",
        "\n",
        "# Specify model training parameters.\n",
        "BATCH_SIZE = 30\n",
        "EPOCHS = 10\n",
        "BUFFER_SIZE = 7000\n",
        "OPTIMIZER = 'Adam'\n",
        "LOSS = dice_loss\n",
        "# update this\n",
        "METRICS =   [metrics.get('RootMeanSquaredError'),\n",
        "    metrics.get('MeanAbsoluteError'),\n",
        "    metrics.get('Accuracy'),\n",
        "    dice_coeff,]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u57RAvvz2v4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfLog()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8OT9lLv34ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!cat myapp.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWXrvBE4607G",
        "colab_type": "text"
      },
      "source": [
        "# Training data\n",
        "\n",
        "Load the data exported from Earth Engine into a `tf.data.Dataset`.  The following are helper functions for that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWZ0UXCVMyJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "  Returns: \n",
        "    A dictionary of tensors, keyed by feature name.\n",
        "  \"\"\"\n",
        "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "\n",
        "\n",
        "def to_tuple(inputs):\n",
        "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
        "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
        "  Args:\n",
        "    inputs: A dictionary of tensors, keyed by feature name.\n",
        "  Returns: \n",
        "    A dtuple of (inputs, outputs).\n",
        "  \"\"\"\n",
        "  inputsList = [inputs.get(key) for key in FEATURES]\n",
        "  stacked = tf.stack(inputsList, axis=0)\n",
        "  # Convert from CHW to HWC\n",
        "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
        "\n",
        "\n",
        "def get_dataset(pattern,flip=False):\n",
        "  \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
        "  Get all the files matching the pattern, parse and convert to tuple.\n",
        "  Args:\n",
        "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "  Returns: \n",
        "    A tf.data.Dataset\n",
        "  \"\"\"\n",
        "  glob = tf.io.gfile.glob(pattern)\n",
        "  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
        "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "  dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
        "  if flip:\n",
        "    dataset = dataset.map(transform)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25VNQgFtvVKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom function to randomly augment the data during training\n",
        "# from kels notebooks\n",
        "# adapted with python random rather than tf. Not sure if it works..\n",
        "import random\n",
        "def transform(features,labels):\n",
        "    x = random.random()\n",
        "    # flip image on horizontal axis\n",
        "    if round(x,2) < 0.12: \n",
        "        feat = tf.image.flip_left_right(features)\n",
        "        labl = tf.image.flip_left_right(labels)\n",
        "    # flip image on vertical axis\n",
        "    elif round(x,2) >=0.12 and round(x,2) < 0.24:\n",
        "        feat = tf.image.flip_up_down(features)\n",
        "        labl = tf.image.flip_up_down(labels)\n",
        "    # transpose image on bottom left corner\n",
        "    elif round(x,2) >=0.24 and round(x,2) < 0.36:\n",
        "        feat = tf.image.flip_left_right(tf.image.flip_up_down(features))\n",
        "        labl = tf.image.flip_left_right(tf.image.flip_up_down(labels))\n",
        "    # rotate to the left 90 degrees\n",
        "    elif round(x,2) >=0.36 and round(x,2) < 0.48:\n",
        "        feat = tf.image.rot90(features,k=1)\n",
        "        labl = tf.image.rot90(labels,k=1)\n",
        "    # rotate to the left 180 degrees\n",
        "    elif round(x,2) >=0.48 and round(x,2) < 0.60:\n",
        "        feat = tf.image.rot90(features,k=2)\n",
        "        labl = tf.image.rot90(labels,k=2)\n",
        "    # rotate to the left 270 degrees\n",
        "    elif round(x,2) >=0.60 and round(x,2) < 0.72:\n",
        "        feat = tf.image.rot90(features,k=3)\n",
        "        labl = tf.image.rot90(labels,k=3)\n",
        "    # transpose image on bottom right corner\n",
        "    elif round(x,2) >=0.72 and round(x,2) < 0.84:\n",
        "        feat = tf.image.flip_left_right(tf.image.rot90(features,k=2))\n",
        "        labl = tf.image.flip_left_right(tf.image.rot90(labels,k=2))\n",
        "    else:\n",
        "        feat = features\n",
        "        labl = labels\n",
        "\n",
        "    return feat,labl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg1fa18336D2",
        "colab_type": "text"
      },
      "source": [
        "Use the helpers to read in the training dataset.  Print the first record to check."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm0qRF0fAYcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_dataset():\n",
        "\t\"\"\"Get the preprocessed training dataset\n",
        "  Returns: \n",
        "    A tf.data.Dataset of training data.\n",
        "  \"\"\"\n",
        "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + TRAINING_BASE + '*'\n",
        "\tdataset = get_dataset(glob,flip=False)\n",
        "\tdataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "training = get_training_dataset()\n",
        "\n",
        "print(iter(training.take(1)).next())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-cQO5RL6vob",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation data\n",
        "\n",
        "Now do the same thing to get an evaluation dataset.  Note that unlike the training dataset, the evaluation dataset has a batch size of 1, is not repeated and is not shuffled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieKTCGiJ6xzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_eval_dataset():\n",
        "\t\"\"\"Get the preprocessed evaluation dataset\n",
        "  Returns: \n",
        "    A tf.data.Dataset of evaluation data.\n",
        "  \"\"\"\n",
        "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + EVAL_BASE + '*'\n",
        "\tdataset = get_dataset(glob)\n",
        "\tdataset = dataset.batch(1).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "evaluation = get_eval_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JIE7Yl87lgU",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "\n",
        "Here we use the Keras implementation of the U-Net model as found [in the TensorFlow examples](https://github.com/tensorflow/models/blob/master/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb).  The U-Net model takes 256x256 pixel patches as input and outputs per-pixel class probability, label or a continuous output.  We can implement the model essentially unmodified, but will use mean squared error loss on the sigmoidal output since we are treating this as a regression problem, rather than a classification problem.  Since impervious surface fraction is constrained to [0,1], with many values close to zero or one, a saturating activation function is suitable here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb--4EG4Xuow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import metrics\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "visible =  layers.Input(shape=[None, None, len(BANDS)])\n",
        "# from stackexchange\n",
        "enocded_imag = layers.Conv2D(64, (7, 7), activation='relu', padding='same')(visible)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "enocded_imag = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(visible)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "enocded_imag = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(enocded_imag)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "enocded_imag = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(enocded_imag)\n",
        "enocded_imag = layers.MaxPooling2D((2, 2), padding='same')(enocded_imag)\n",
        "\n",
        "decoded_imag = layers.Conv2D(8, (2, 2), activation='relu', padding='same')(enocded_imag)\n",
        "decoded_imag = layers.UpSampling2D((2, 2),interpolation='bilinear')(decoded_imag)\n",
        "decoded_imag = layers.BatchNormalization()(decoded_imag)\n",
        "decoded_imag = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(decoded_imag)\n",
        "decoded_imag = layers.UpSampling2D((2, 2),interpolation='bilinear')(decoded_imag)\n",
        "decoded_imag = layers.BatchNormalization()(decoded_imag)\n",
        "decoded_imag = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(decoded_imag)\n",
        "decoded_imag = layers.UpSampling2D((2, 2),interpolation='bilinear')(decoded_imag)\n",
        "decoded_imag = layers.BatchNormalization()(decoded_imag)\n",
        "decoded_imag = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(decoded_imag)\n",
        "\n",
        "\n",
        "outBranch = layers.Conv2D(128, 3, activation='relu', \n",
        "                          padding='same',name=\"out_block_conv1\")(decoded_imag)\n",
        "outBranch = layers.SpatialDropout2D(rate=0.2,seed=1,name=\"out_block_spatialdrop\")(outBranch)\n",
        "outBranch = layers.BatchNormalization(name=\"out_block_batchnorm1\")(outBranch)\n",
        "outBranch = layers.Conv2D(len(RESPONSE), (1, 1), activation='relu')(outBranch)\n",
        "outputs = layers.Activation(\"softmax\")(outBranch)\n",
        "model = models.Model(inputs=visible, outputs=outputs)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "plot_model(model, to_file='convolutional_neural_network.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_izh_qTye3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# small conv for 4x4\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import metrics\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "visible =  layers.Input(shape=[None, None, len(BANDS)])\n",
        "# from stackexchange\n",
        "enocded_imag = layers.Conv2D(128, (1, 1), activation='relu', padding='same')(visible)\n",
        "\n",
        "\n",
        "outBranch = layers.BatchNormalization(name=\"out_block_batchnorm1\")(enocded_imag)\n",
        "outBranch = layers.Conv2D(len(RESPONSE), (1, 1), activation='relu')(outBranch)\n",
        "outputs = layers.Activation(\"softmax\")(outBranch)\n",
        "model = models.Model(inputs=visible, outputs=outputs)\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "# plot graph\n",
        "plot_model(model, to_file='convolutional_neural_network.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49TETp8tFWjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.compile(\n",
        "\t\toptimizer=optimizers.Adam(lr=0.001), \n",
        "\t\tloss=dice_loss_soft,\n",
        "\t\tmetrics=[metrics.get('CategoricalAccuracy')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzzaWxOhSxBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = model\n",
        "MODEL_FOLDER = 'tinyswig'\n",
        "modelDir = 'gs://{}/{}/{}'.format(BUCKET,FOLDER,MODEL_FOLDER)\n",
        "\n",
        "history = m.fit(\n",
        "    x=training, \n",
        "    epochs=15,#EPOCHS, \n",
        "    steps_per_epoch=int(TRAIN_SIZE / 1), \n",
        "    validation_data=evaluation,\n",
        "    validation_steps=EVAL_SIZE)\n",
        "\n",
        "\n",
        "# m.save(modelDir, save_format='tf')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m-3cRvk4XSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.save(modelDir, save_format='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DCHMtiqYlbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the results of model training\n",
        "# get numpy and matplotlib.pyplot\n",
        "# from kels notebooks\n",
        "%pylab inline\n",
        "fig, ax = plt.subplots(nrows=2, sharex=True, figsize=(10,5.5))\n",
        "\n",
        "ax[0].plot(history.history['loss'],color='#1f77b4',label='Training Loss')\n",
        "ax[0].plot(history.history['val_loss'],linestyle=':',marker='o',markersize=3,color='#1f77b4',label='Validation Loss')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_ylim(0.0,0.4)\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(history.history['categorical_accuracy'],color='#ff7f0e',label='Training Acc.')\n",
        "ax[1].plot(history.history['val_categorical_accuracy'],linestyle=':',marker='o',markersize=3,color='#ff7f0e',label='Validation Acc.')\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].legend(loc=\"lower right\")\n",
        "\n",
        "ax[1].set_xticks(history.epoch)\n",
        "ax[1].set_xticklabels(range(1,len(history.epoch)+1))\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].set_ylim(0.0,1)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# plt.savefig(\"/content/drive/My Drive/landsat_qa_samples/training.png\",dpi=300,)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu_E7OTDBCoS",
        "colab_type": "text"
      },
      "source": [
        "# Training the model\n",
        "\n",
        "You train a Keras model by calling `.fit()` on it.  Here we're going to train for 10 epochs, which is suitable for demonstration purposes.  For production use, you probably want to optimize this parameter, for example through [hyperparamter tuning](https://cloud.google.com/ml-engine/docs/tensorflow/using-hyperparameter-tuning)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2XrwZHp66j4",
        "colab_type": "text"
      },
      "source": [
        "Note that the notebook VM is sometimes not heavy-duty enough to get through a whole training job, especially if you have a large buffer size or a large number of epochs.  You can still use this notebook for training, but may need to set up an alternative VM ([learn more](https://research.google.com/colaboratory/local-runtimes.html)) for production use.  Alternatively, you can package your code for running large training jobs on Google's AI Platform [as described here](https://cloud.google.com/ml-engine/docs/tensorflow/trainer-considerations).  The following code loads a pre-trained model, which you can use for predictions right away."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YcsnqOA2du_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.tools import saved_model_utils\n",
        "\n",
        "\n",
        "meta_graph_def = saved_model_utils.get_meta_graph_def(modelDir, 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "\n",
        "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
        "# model only has a single input and a single output.\n",
        "input_name = None\n",
        "for k,v in inputs.items():\n",
        "  input_name = v.name\n",
        "  break\n",
        "\n",
        "output_name = None\n",
        "for k,v in outputs.items():\n",
        "  output_name = v.name\n",
        "  break\n",
        "\n",
        "# Make a dictionary that maps Earth Engine outputs and inputs to \n",
        "# AI Platform inputs and outputs, respectively.\n",
        "import json\n",
        "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
        "output_dict = \"'\" + json.dumps({output_name: \"class\"}) + \"'\"\n",
        "\n",
        "# Put the EEified model next to the trained model directory.\n",
        "# TODO: add eeidied dir, project into to log, add output name\n",
        "EEIFIED_DIR = '{}/eeified'.format(modelDir)\n",
        "PROJECT = 'john-ee-282116'\n",
        "print(input_dict,output_dict)\n",
        "# You need to set the project before using the model prepare command.\n",
        "!earthengine set_project {PROJECT}\n",
        "!earthengine model prepare --source_dir {modelDir} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TaQgGhcePnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelDir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E0OpHQo5DKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "MODEL_NAME = 'tinyswig'\n",
        "\n",
        "VERSION_NAME = 'v' + str(int(time.time()))\n",
        "print('Creating version: ' + VERSION_NAME)\n",
        "\n",
        "!gcloud ai-platform models create {MODEL_NAME} --project {PROJECT}\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --origin {EEIFIED_DIR} \\\n",
        "  --runtime-version=2.2 \\\n",
        "  --framework \"TENSORFLOW\" \\\n",
        "  --python-version=3.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RJpNfEUS1qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a trained model. \n",
        "MODEL_DIR = 'gs://ee-tf/tahoe-ogfw-02292020/model-ogwf-256'\n",
        "m = tf.contrib.saved_model.load_keras_model(MODEL_DIR)\n",
        "help(m.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}