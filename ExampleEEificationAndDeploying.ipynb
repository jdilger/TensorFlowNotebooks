{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExampleEEificationAndDeploying.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPG1n8ftnrkvZhOut2/c7jS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdilger/TensorFlowNotebooks/blob/master/ExampleEEificationAndDeploying.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example notebook on loading a saved model and working through the steps to EE-ify the model and deplay to the AI platform for inferance in GEE.\n",
        "\n",
        "There have been some minor updates since the first pass of notebooks we have used for this process which are reflected in the current example of hosting a [Hostable DNN for prediction in Earth Engine](https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/Earth_Engine_TensorFlow_AI_Platform.ipynb).\n",
        "\n"
      ],
      "metadata": {
        "id": "GJ6YYZBtWdRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authentication steps"
      ],
      "metadata": {
        "id": "lfsrNMNEXIPG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOgyj7uWOYDJ",
        "outputId": "fe02e87e-cb4f-4532-fd8a-b6c146cb3dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Cloud authentication.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "try:\n",
        "    ee.Initialize()\n",
        "except Exception as e:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize()"
      ],
      "metadata": {
        "id": "JGjz4udpOhyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "tNzRxrXROibX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load a saved model\n",
        "\n",
        "Example loads a saved keras model in .h5 format. A TF dir could be loaded in the same manner as well.\n",
        "\n",
        "Model src: 'gs://landfire/vgg16unet_model_jjd_mse_sigmoid.h5'"
      ],
      "metadata": {
        "id": "wxrVP6F_XQ6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'vgg16unet_model_jjd_mse_sigmoid.h5'\n",
        "BUCKET = 'landfire'\n",
        "\n",
        "\n",
        "model_path =  f\"gs://{BUCKET}/{MODEL_NAME}\"\n",
        "# model.save(f\"{MODEL_NAME}.h5\")\n",
        "new_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "metadata": {
        "id": "dh4sz2oDPFq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save the trained model\n",
        "\n",
        "Export the trained model to TensorFlow SavedModel format in your cloud storage bucket. The Cloud Platform storage browser is useful for checking on these saved models. (taken directly from Hostable DNN for prediction in Earth Engine example).\n",
        "\n"
      ],
      "metadata": {
        "id": "e3r8upBzYEtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: do we need to save it as an 'estimator' TF DIR? or could we keep it in the .h5 format?\n",
        "\n",
        " A. I think so... get_meta_graph_def(TF_FIR) reads the graph from a directory. \n",
        " "
      ],
      "metadata": {
        "id": "Fs3mjiYoVs0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  save the model as a TF Estimator which is what \n",
        "MODEL_NAME_ESTIMATOR = MODEL_NAME.split('.')[0] + '_ESTIMATOR'\n",
        "TF_DIR = 'gs://{}/{}'.format(BUCKET,MODEL_NAME_ESTIMATOR)\n",
        "print(TF_DIR)\n",
        "tf.keras.models.save_model(new_model,TF_DIR,save_format='tf')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAHv9ll6Q7l3",
        "outputId": "1f6bf8aa-efaf-4296-e059-e9aec5d128ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://landfire/vgg16unet_model_jjd_mse_sigmoid_ESTIMATOR\n",
            "INFO:tensorflow:Assets written to: gs://landfire/vgg16unet_model_jjd_mse_sigmoid_ESTIMATOR/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EEification\n",
        "\n",
        "EEIfication prepares the model for hosting on [Google AI Platform](https://cloud.google.com/ai-platform).  Learn more about EEification from [this doc](https://developers.google.com/earth-engine/tensorflow#interacting-with-models-hosted-on-ai-platform).  First, get (and SET) input and output names of the nodes.  **CHANGE THE OUTPUT NAME TO SOMETHING THAT MAKES SENSE FOR YOUR MODEL!**  Keep the input name of 'array', which is how you'll pass data into the model (as an array image)."
      ],
      "metadata": {
        "id": "o3lpqeNWZT8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.tools import saved_model_utils\n",
        "\n",
        "meta_graph_def = saved_model_utils.get_meta_graph_def(TF_DIR, 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "\n",
        "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
        "# model only has a single input and a single output.\n",
        "input_name = None\n",
        "for k,v in inputs.items():\n",
        "    input_name = v.name\n",
        "    break\n",
        "\n",
        "output_name = None\n",
        "for k,v in outputs.items():\n",
        "    output_name = v.name\n",
        "    break\n",
        "\n",
        "# Make a dictionary that maps Earth Engine outputs and inputs to \n",
        "# AI Platform inputs and outputs, respectively.\n",
        "import json\n",
        "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
        "output_dict = \"'\" + json.dumps({output_name: 'pools2BP'}) + \"'\"\n",
        "print(input_dict)\n",
        "print(output_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dlsBPoiSP6k",
        "outputId": "d68218a8-4747-44de-fe8c-8b66ed20f00b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'{\"serving_default_input:0\": \"array\"}'\n",
            "'{\"StatefulPartitionedCall:0\": \"pools2BP\"}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the EEifier\n",
        "\n",
        "The actual EEification is handled by the `earthengine model prepare` command.  Note that you will need to set your Cloud Project prior to running the command."
      ],
      "metadata": {
        "id": "--2jubR2ZrWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the EEified model next to the trained model directory.\n",
        "EEIFIED_DIR = 'gs://{}/eeified_{}/'.format(BUCKET,MODEL_NAME_ESTIMATOR)\n",
        "# change to your specific project\n",
        "PROJECT = 'pyregence-ee'\n",
        "REGION = 'us-central1'\n",
        "# # You need to set the project before using the model prepare command.\n",
        "!earthengine set_project {PROJECT}\n",
        "!earthengine model prepare --source_dir {TF_DIR} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysqZ00LmSZhT",
        "outputId": "556c8ee4-ec04-4afd-b96c-dfcefef725a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved project id\n",
            "Warning: TensorFlow Addons not found. Models that use non-standard ops may not work.\n",
            "Success: model at 'gs://landfire/eeified_vgg16unet_model_jjd_mse_sigmoid_ESTIMATOR/' is ready to be hosted in AI Platform.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy and host the EEified model on AI Platform\n",
        "\n",
        "Now there is another TensorFlow `SavedModel` stored in `EEIFIED_DIR` ready for hosting by AI Platform.  Do that from the `gcloud` command line tool, installed in the Colab runtime by default.  Be sure to specify a regional model with the `REGION` parameter.  Note that the `MODEL_NAME` must be unique.  If you already have a model by that name, either name a new model or a new version of the old model.  The [Cloud Console AI Platform models page](https://console.cloud.google.com/ai-platform/models) is useful for monitoring your models.\n",
        "\n",
        "**If you change anything about the trained model, you'll need to re-EEify it and create a new version!**"
      ],
      "metadata": {
        "id": "6CHbGuXwZxWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai-platform models create {MODEL_NAME_ESTIMATOR} --project {PROJECT} --region {REGION}"
      ],
      "metadata": {
        "id": "hNnN5kXZTaJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "MODEL_NAME = MODEL_NAME_ESTIMATOR\n",
        "VERSION_NAME = 'v' + str(int(time.time()))\n",
        "print('Creating version: ' + VERSION_NAME)\n",
        "\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --region {REGION} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --origin {EEIFIED_DIR} \\\n",
        "  --framework \"TENSORFLOW\" \\\n",
        "  --runtime-version=2.3 \\\n",
        "  --python-version=3.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGYjek1HSubL",
        "outputId": "f712685b-00cf-4fec-8d64-2402211744ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating version: v1647813426\n",
            "Using endpoint [https://us-east1-ml.googleapis.com/]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('MODEL_NAME=',MODEL_NAME)\n",
        "print('VERSION_NAME=',VERSION_NAME)\n",
        "print('PROJECT=',PROJECT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvi4PqsrdJu7",
        "outputId": "20c85a98-62c1-4fbb-ed78-1b93384acd32"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL_NAME= vgg16unet_model_jjd_mse_sigmoid_ESTIMATOR\n",
            "VERSION_NAME= v1647813426\n",
            "PROJECT= pyregence-ee\n"
          ]
        }
      ]
    }
  ]
}